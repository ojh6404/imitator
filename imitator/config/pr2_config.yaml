ros:
  rate: 10
  action_type: "end_effector" # TODO
  message_filters:
    slop: 0.1
    queue_size: 1000
  additional_topics:
    - "/tf"
    - "/joint_states"
    - "/kinect_head/depth_registered/image_rect"
    - "/kinect_head/rgb/camera_info"
    - "/eus_imitation/l_arm_state"
    - "/eus_imitation/r_arm_state"
    - "/eus_imitation/all_robot_state"
    - "/spacenav/joy"
    - "/controller_LHR_FD35BD42/joy"
    - "/controller_LHR_F7AFBF47/joy"

obs: # input into policy
  kinect_head_image:
    topic_name: "/kinect_head/rgb/image_rect_color/compressed"
    msg_type: "CompressedImage"
    modality: "ImageModality"
    normalize: False
    data_augmentation: True
    obs_encoder:
      model: "Resnet"
      model_path: null
      model_kwargs:
        input_size: [224, 224]
        input_channel: 3
        resnet_type: "resnet18"
        input_coord_conv: False
        pretrained: False,
        latent_dim: 64
        pool: "SpatialSoftmax"
        pool_kwargs:
          num_kp: 32
          temperature: 1.0
          learnable_temperature: False
          output_variance: False
          noise_std: 0.0
      trainable: True
      input_dim: [224, 224, 3]
      activation: "ReLU"
      layer_dims: null
      output_dim: 64
      has_decoder: False
      freeze: False
  pr2_eef_pos:
    topic_name: "/eus_imitation/robot_state"
    msg_type: "Float32MultiArrayStamped"
    modality: "FloatVectorModality"
    normalize: True
    obs_encoder:
      input_dim: 7
      output_dim: 7
      layer_dims: null
      activation: "ReLU" # [ReLU, Tanh...]
actions:
  topic_name: "/eus_imitation/robot_action"
  msg_type: "Float32MultiArrayStamped"
  modality: "FloatVectorModality"
  dim: 7
  normalize: True

network:
  policy:
    model: "TransformerActor"
    model_path: null
    transformer:
      type: "GPT"
      transformer_num_layers: 6
      transformer_num_heads: 8
      transformer_embed_dim: 512
      context_length: 20
      attn_dropout: 0.1
      block_dropout: 0.1
      activation: "gelu"
    mlp_decoder:
      layer_dims: [128, 128, 128]
      activation: "ReLU"
      squash_output: True
    train:
      lr: 1e-4
      lr_scheduler: True
      optimizer: "Adam"
      batch_size: 128
      seq_length: 10 # equal to rnn seq_length if RNNActor
      weight:
        l1: 0.0
        l2: 1.0

dataset:
  dataset_keys: ["actions"]
  load_next_obs: True
  # frame_stack: 1
  frame_stack: 20
  pad_frame_stack: True
  pad_seq_length: True
  get_pad_mask: False
  goal_mode: null
  hdf5_cache_mode: null
  hdf5_use_swmr: True
